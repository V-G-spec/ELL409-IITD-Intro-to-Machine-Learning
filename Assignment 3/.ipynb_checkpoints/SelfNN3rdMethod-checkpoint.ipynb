{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07412e84-02c6-4388-bbb5-d0cd5ca7f19f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5937564c-d453-48e6-85dd-e9b4f57b2a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "random_state = 7\n",
    "# https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0737d3-9c71-444d-aa8f-83ccedc3bb4e",
   "metadata": {},
   "source": [
    "## User Stuff (Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "47b48019-a7b7-457f-bdd4-4c4eab1dae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INPUTS\n",
    "input_shape = (28,28) #I set this depending upon picture\n",
    "\n",
    "prod = 1\n",
    "for i in input_shape:\n",
    "    prod=prod*i\n",
    "\n",
    "num_nodes = [prod, 128, 10] #List of nodes in each layer \n",
    "\n",
    "# input_dim=prod # product of everything of input_shape\n",
    "# assert(num_nodes[0]==input_dim)\n",
    "\n",
    "# output_dim= num_nodes[-1] # Total number of classes\n",
    "\n",
    "activation_fn= ['relu'] #List of activation functions for each layer\n",
    "assert(len(activation_fn) == len(num_nodes)-2) #Because last will be softmax\n",
    "\n",
    "typ= ['fc', 'activation', 'fc', 'softmax'] #I set it mp. len = 2*len(act_fn)-2\n",
    "# ALWAYS of the type fc,act,fc,act,...,fc,softmax\n",
    "# DO NOT ADD SOFTMAX ANYWHERE ELSE\n",
    "assert(len(typ) == 2*len(num_nodes)-2)\n",
    "\n",
    "#### TRAINING RELATED HYPERPARAMETERS\n",
    "EPOCHS = 10\n",
    "initial_learning_rate = 0.1\n",
    "cost_fn = 'mse'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb9b73-369c-43da-adb5-84182c8ff47e",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "76c21507-7afe-48a3-a149-b8f1b407417d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n",
      "1306  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2037  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "568   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1897  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2498  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "      778  779  780  781  782  783  784  \n",
      "1306  0.0  0.0  0.0  0.0  0.0  0.0  7.0  \n",
      "2037  0.0  0.0  0.0  0.0  0.0  0.0  5.0  \n",
      "568   0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "1897  0.0  0.0  0.0  0.0  0.0  0.0  9.0  \n",
      "2498  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "      0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n",
      "2536  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1452  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "149   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1757  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "218   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "      778  779  780  781  782  783  784  \n",
      "2536  0.0  0.0  0.0  0.0  0.0  0.0  6.0  \n",
      "1452  0.0  0.0  0.0  0.0  0.0  0.0  6.0  \n",
      "149   0.0  0.0  0.0  0.0  0.0  0.0  6.0  \n",
      "1757  0.0  0.0  0.0  0.0  0.0  0.0  8.0  \n",
      "218   0.0  0.0  0.0  0.0  0.0  0.0  6.0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "(2400, 784) (2400, 1) (600, 784) (600, 1)\n"
     ]
    }
   ],
   "source": [
    "#<Something>\n",
    "file_name = '2019EE10143.csv'\n",
    "split_frac = 0.8\n",
    "    \n",
    "def load_data(file_name, split_frac):\n",
    "    df = pd.read_csv(file_name, header=None)\n",
    "    cols = len(df.columns) #785\n",
    "    num_ft = cols-1\n",
    "\n",
    "    df = df.sample(frac=1., random_state=random_state)\n",
    "    train_df = df[:int(split_frac*len(df))]\n",
    "    print(train_df.head())\n",
    "    test_df = df[int(split_frac*len(df)):]\n",
    "    print(test_df.head())\n",
    "    X_train_temp = train_df.loc[:, [i for i in range(num_ft)]]\n",
    "    y_train_temp = train_df.loc[:, [num_ft]]\n",
    "    X_test_temp = test_df.loc[:, [i for i in range(num_ft)]]\n",
    "    y_test_temp = test_df.loc[:, [num_ft]]\n",
    "\n",
    "    train_X = np.array(X_train_temp.values)\n",
    "    train_y = np.array(y_train_temp.values)\n",
    "    test_X = np.array(X_test_temp.values)\n",
    "    test_y = np.array(y_test_temp.values)\n",
    "    \n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "train_X, train_y, test_X, test_y = load_data(file_name, split_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c54d48-ec6f-431b-ba64-4108a9cce139",
   "metadata": {},
   "source": [
    "# Let's get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977582a9-2733-4bc8-8b31-f3e846caf558",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8e8e037b-1b40-47a2-842e-c8f98ca04aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds_idx(N, nFolds, seed=42):\n",
    "    \"\"\"\n",
    "    Randomly permute [0,N] and extract indices for each fold\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    rnd_idx = np.random.permutation(N)\n",
    "    N_fold = N//nFolds\n",
    "    indices = []\n",
    "    for i in range(nFolds):\n",
    "        start = i*N_fold\n",
    "        end = min([(i+1)*N_fold, N])\n",
    "        # if (N<end):\n",
    "        #     end = N\n",
    "        indices.append(rnd_idx[start:end])\n",
    "    return indices\n",
    "\n",
    "\n",
    "def convToList(y, out_dim):\n",
    "    assert(int(y)==y)\n",
    "    tmp = np.zeros(out_dim, dtype=np.int32)\n",
    "    tmp[int(y)] = 1\n",
    "    return tmp\n",
    "\n",
    "def showImage(img, label):\n",
    "    picAr = np.array(img, dtype='float')\n",
    "    roughSd = int(math.sqrt(img.size))\n",
    "    pic = picAr.reshape((roughSd, roughSd)).T\n",
    "    plt.imshow(pic) #cmap='grey'\n",
    "    lb = str(label)\n",
    "    plt.title('label for this image is',lb)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def act_fn(typ, Z):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    typ -- sigmoid/RELU\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z)/RELU(z)/tanh(Z), same shape as Z\n",
    "    \"\"\"\n",
    "    if (typ.lower()=='sigmoid'):\n",
    "        a = 1/(1+np.exp(-Z))\n",
    "    elif (typ.lower()=='relu'):\n",
    "        a = np.maximum(0,Z)\n",
    "    elif (typ.lower()=='tanh'):\n",
    "        a= np.tanh(Z)\n",
    "        \n",
    "    assert(a.shape == Z.shape)\n",
    "    return a\n",
    "    \n",
    "def back_fn(typ, Z):\n",
    "    if (typ.lower()=='relu'):\n",
    "        #dZ = np.array(Z, copy=True)\n",
    "        # When z <= 0, set dz to 0. \n",
    "        #dZ[Z <= 0] = 0\n",
    "        dZ = np.array(Z>=0).astype('int')\n",
    "    elif (typ.lower()=='sigmoid'):\n",
    "        dZ = np.exp(-Z)/(1+np.exp(-Z))**2\n",
    "    elif (typ.lower()=='tanh'):\n",
    "        dZ = 1-np.tanh(Z)**2\n",
    "    \n",
    "    assert(dZ.shape==Z.shape)\n",
    "    return dZ\n",
    "\n",
    "    \n",
    "def forCost(typ, logits, yt):\n",
    "    y = convToList(yt, logits.shape[1])\n",
    "    y = np.reshape(y, logits.shape)\n",
    "    #print(y.shape, logits.shape)\n",
    "    #assert(y.shape==logits.shape)\n",
    "    if (typ.lower()=='mse'):\n",
    "        delt = np.power(logits-y,2)\n",
    "        ret= np.mean(delt)\n",
    "        #ret/=y.shape\n",
    "    elif (typ.lower()=='sse'):\n",
    "        delt = np.power(logits-y,2)\n",
    "        ret= np.sum(delt)\n",
    "        ret/=2\n",
    "    else:\n",
    "        print(\"Lmao ded, gonna get an error\")\n",
    "    return ret\n",
    "\n",
    "\n",
    "def backCost(typ, logits, yt):\n",
    "    y = convToList(yt, logits.shape[1])\n",
    "    y = np.reshape(y, logits.shape)\n",
    "    if (typ.lower()=='mse'):\n",
    "        delt=(logits-y)\n",
    "        ret = 2*delt/y.size\n",
    "    elif (typ.lower()=='sse'):\n",
    "        ret = logits-y\n",
    "    else:\n",
    "        print(\"Lmao ded, gonna get an error\")\n",
    "    return ret\n",
    "\n",
    "\n",
    "def update_lr(eta0, iteration):\n",
    "#         if (self.lr_strat == 0):\n",
    "#             return eta0\n",
    "#         else:\n",
    "    return eta0/((iteration+1)**0.5)\n",
    "\n",
    "def normalize(X):\n",
    "    return X/255\n",
    "\n",
    "def predict(network, xin):\n",
    "    out=np.reshape(xin, (1, -1))\n",
    "    for layer in network:\n",
    "        out = layer.forward(out)\n",
    "    return out\n",
    "\n",
    "def accuracy(network, test_X, test_y):\n",
    "    corr = 0\n",
    "    for (x,y) in zip(test_X, test_y):\n",
    "        if (np.argmax(y) == np.argmax(predict(network, x))):\n",
    "            corr+=1\n",
    "    corr/=len(test_y)\n",
    "    return 100*corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07395766-6245-4eeb-af13-9822f7806d76",
   "metadata": {},
   "source": [
    "## Class (Cuz I'm fancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9822307d-325b-4a36-80a2-8af7a5adc1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Layers:\n",
    "    # def __init__(self, input_shape=None, input_dim=None, output_dim=None, act_fn=None, typ=None):\n",
    "        \n",
    "    def __init__(self, input_shape=None, input_dim=None, output_dim=None, act_fnc=None, typ=None):\n",
    "        self.typ=typ\n",
    "        if(typ.lower()=='softmax'):\n",
    "            self.input_dim = input_dim\n",
    "        # elif(typ.lower()=='flatten'):\n",
    "        #     self.inshape = input_shape\n",
    "        elif(typ.lower()=='activation'):\n",
    "            self.act_fun = act_fnc\n",
    "        elif(typ.lower()=='fc'): #FC\n",
    "            self.input_dim = input_dim\n",
    "            self.output_dim = output_dim\n",
    "            ssz = np.sqrt((input_dim+output_dim)/2)\n",
    "            self.weights = np.random.randn(input_dim, output_dim)/ssz\n",
    "            self.bias = np.random.randn(1, output_dim)/ssz\n",
    "        else:\n",
    "            print(\"Oops! Wrong layer type. Gonna go die\")\n",
    "\n",
    "    def forward(self, xin):\n",
    "        if(self.typ.lower()=='softmax'):\n",
    "            self.inputSoft = xin\n",
    "            #exps = np.exp(xin - xin.max())\n",
    "            exps = np.exp(xin)\n",
    "            self.outSoft = exps/np.sum(exps)\n",
    "            return self.outSoft\n",
    "        # elif (self.typ.lower()=='flatten'):\n",
    "        #     return np.reshape(xin, (1, -1))\n",
    "        elif(self.typ.lower()=='activation'):\n",
    "            self.inputAct = xin\n",
    "            return act_fn(self.act_fun, xin)\n",
    "        elif(self.typ.lower()=='fc'): #FC\n",
    "            self.inputFC = xin\n",
    "            return np.dot(xin, self.weights)+self.bias\n",
    "\n",
    "    def backward(self, out_err, lr):\n",
    "        if(self.typ.lower()=='softmax'):\n",
    "            in_err=np.zeros(out_err.shape)\n",
    "            out=np.tile(self.outSoft.T, self.input_dim)\n",
    "            return self.outSoft*np.dot(out_err, np.identity(self.input_dim)-out) ###Can have problems\n",
    "            #tmp = self.inputSoft\n",
    "            #exps = np.exp(tmp-tmp.max())\n",
    "            #tmp2= exps/np.sum(exps)*(1-exps/np.sum(exps))\n",
    "            #return out_err*tmp2\n",
    "        # elif(typ.lower()=='flatten'):\n",
    "        #    return np.reshape(out_err, self.inshape)\n",
    "        elif(self.typ.lower()=='activation'):\n",
    "            return out_err*back_fn(self.act_fun, self.inputAct)\n",
    "        elif(self.typ.lower()=='fc'): #FC\n",
    "            in_err = np.dot(out_err, self.weights.T)\n",
    "#             if(self.inputFC.T.shape[-1] != out_err.shape[0]):\n",
    "#                 print(self.inputFC.T.shape[-1], out_err.shape[0])\n",
    "            assert(self.inputFC.T.shape[-1] == out_err.shape[0])\n",
    "            wt_err = np.dot(self.inputFC.T, out_err)\n",
    "            self.weights-=lr*wt_err\n",
    "            self.bias-=lr*out_err\n",
    "            return in_err\n",
    "\n",
    "    def rettyp(self):\n",
    "        return self.typ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ba9b8-bcfa-4867-8c47-792dc830f6f3",
   "metadata": {},
   "source": [
    "## Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "22a4aeb0-0bd9-415f-9cf7-d85f1a9253f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net(typ, num_nodes, activation_fn):\n",
    "    network = []\n",
    "    for idx, ll in enumerate(typ):\n",
    "        if (ll=='fc'):\n",
    "            assert(idx%2==0)\n",
    "            network.append(Layers(typ=ll, input_dim = num_nodes[idx//2], output_dim = num_nodes[(idx//2)+1]))\n",
    "            print(ll, num_nodes[idx//2], num_nodes[(idx//2)+1])\n",
    "        elif (ll=='activation'):\n",
    "            assert((idx-1)%2==0)\n",
    "            network.append(Layers(typ=ll, act_fnc=activation_fn[(idx-1)//2]))\n",
    "            print(ll, activation_fn[(idx-1)//2])\n",
    "        elif (ll=='softmax'):\n",
    "            network.append(Layers(typ=ll, input_dim=num_nodes[-1]))\n",
    "            print(ll, num_nodes[-1])\n",
    "        else:\n",
    "            print(\"You did something wrong there homie. Try again\")\n",
    "    \n",
    "    \n",
    "#     for layer in network:\n",
    "#         print(layer.rettyp())\n",
    "    \n",
    "    return network\n",
    "    \n",
    "### TO DO:\n",
    "### Make function in utilities to create a network, and a function to train\n",
    "### Functions to load data and k-fold cv splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc5c45-713a-4824-9122-14f61a2a4c64",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6b81de05-5d22-4dc4-85c7-b8162de8d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, Xtrain, ytrain, epochs=50, initlr=0.1, cost_fn='mse'):\n",
    "    error = []\n",
    "    for epoch in range(epochs):\n",
    "        #lr = initlr\n",
    "        lr = update_lr(initlr, epoch)\n",
    "        err = 0\n",
    "        for (x_b,y_b) in zip(Xtrain, ytrain):\n",
    "            out = np.reshape(x_b, (1, -1))\n",
    "            for layer in network:\n",
    "                out=layer.forward(out)\n",
    "            \n",
    "            err+=forCost(cost_fn, out, y_b)\n",
    "            #print(err)\n",
    "            rev_err=backCost(cost_fn, out, y_b)\n",
    "            \n",
    "            for layer in reversed(network):\n",
    "                rev_err = layer.backward(rev_err, lr)\n",
    "                \n",
    "        err=err/len(Xtrain)\n",
    "        print('%d/%d, Error=%f' % (epoch+1, epochs, err))\n",
    "        error.append(err)\n",
    "        \n",
    "    #for i in range(EPOCHS):\n",
    "        \n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89e8ed-baf0-4041-8958-a0947a9089fd",
   "metadata": {},
   "source": [
    "## Let's get Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3ed500fb-66cf-45ce-ac24-110b4ed2c3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc 784 128\n",
      "activation relu\n",
      "fc 128 10\n",
      "softmax 10\n",
      "1/10, Error=0.047389\n",
      "2/10, Error=0.020811\n",
      "3/10, Error=0.015886\n",
      "4/10, Error=0.013482\n",
      "5/10, Error=0.011953\n",
      "6/10, Error=0.010831\n",
      "7/10, Error=0.009950\n",
      "8/10, Error=0.009221\n",
      "9/10, Error=0.008603\n",
      "10/10, Error=0.008072\n",
      "Train accuracy: 10.468750\n",
      "Dev accuracy: 0.000000\n",
      "Test accuracy: 0.000000\n",
      "1/10, Error=0.011073\n",
      "2/10, Error=0.008565\n",
      "3/10, Error=0.007261\n",
      "4/10, Error=0.006528\n",
      "5/10, Error=0.006045\n",
      "6/10, Error=0.005671\n",
      "7/10, Error=0.005372\n",
      "8/10, Error=0.005120\n",
      "9/10, Error=0.004913\n",
      "10/10, Error=0.004730\n",
      "Train accuracy: 9.322917\n",
      "Dev accuracy: 0.000000\n",
      "Test accuracy: 0.000000\n",
      "1/10, Error=0.007222\n",
      "2/10, Error=0.005635\n",
      "3/10, Error=0.004869\n",
      "4/10, Error=0.004457\n",
      "5/10, Error=0.004144\n",
      "6/10, Error=0.003930\n",
      "7/10, Error=0.003771\n",
      "8/10, Error=0.003644\n",
      "9/10, Error=0.003540\n",
      "10/10, Error=0.003452\n",
      "Train accuracy: 10.052083\n",
      "Dev accuracy: 0.000000\n",
      "Test accuracy: 0.000000\n",
      "1/10, Error=0.004658\n",
      "2/10, Error=0.003711\n",
      "3/10, Error=0.003407\n",
      "4/10, Error=0.003238\n",
      "5/10, Error=0.003099\n",
      "6/10, Error=0.002979\n",
      "7/10, Error=0.002887\n",
      "8/10, Error=0.002807\n",
      "9/10, Error=0.002733\n",
      "10/10, Error=0.002669\n",
      "Train accuracy: 10.833333\n",
      "Dev accuracy: 0.000000\n",
      "Test accuracy: 0.000000\n",
      "1/10, Error=0.003327\n",
      "2/10, Error=0.002848\n",
      "3/10, Error=0.002662\n",
      "4/10, Error=0.002568\n",
      "5/10, Error=0.002499\n",
      "6/10, Error=0.002438\n",
      "7/10, Error=0.002377\n",
      "8/10, Error=0.002317\n",
      "9/10, Error=0.002269\n",
      "10/10, Error=0.002232\n",
      "Train accuracy: 10.312500\n",
      "Dev accuracy: 0.000000\n",
      "Test accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "# train_X\n",
    "# train_y\n",
    "# test_X\n",
    "# test_y\n",
    "\n",
    "N = len(train_X)\n",
    "assert(N==len(train_y))\n",
    "idx_all = np.arange(0, N)\n",
    "idx_folds = get_folds_idx(N, folds, seed=random_state) # list of list of fold indices\n",
    "\n",
    "network = create_net(typ, num_nodes, activation_fn)\n",
    "train_acc = np.array([])\n",
    "dev_acc = np.array([])\n",
    "test_acc = np.array([])\n",
    "# for layer in network:\n",
    "#     print(layer.rettyp())\n",
    "for i,indcs in enumerate(idx_folds):\n",
    "    idx_train = np.delete(idx_all, indcs)\n",
    "    X_train, y_train = train_X[idx_train], train_y[idx_train]\n",
    "    X_valid, y_valid = train_X[indcs], train_y[indcs]\n",
    "#     X_train = normalize(X_train)\n",
    "#     X_valid = normalize(X_valid)\n",
    "#     test_X = normalize(test_X)\n",
    "    \n",
    "    error = train(network, X_train, y_train, epochs=EPOCHS, initlr = initial_learning_rate, cost_fn=cost_fn)\n",
    "    train_acc.append(accuracy(network, X_train, y_train))\n",
    "    train_acc.append(accuracy(network, X_valid, y_valid))\n",
    "    train_acc.append(accuracy(network, X_test, y_test))\n",
    "#     print('Train accuracy: %f'%())\n",
    "#     print('Dev accuracy: %f'%(accuracy(network, X_valid, y_valid)))\n",
    "#     print('Test accuracy: %f'%(accuracy(network, test_X, test_y)))\n",
    "\n",
    "print('Mean train accuracy: %f'%(np.mean(train_acc)))\n",
    "print('Mean dev accuracy: %f'%(np.mean(dev_acc)))\n",
    "print('Mean test accuracy: %f'%(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be073e9-1d30-49f9-b3cd-e632c9fcc387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
