{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae78186-7827-44d6-bc5d-45080db3b8a1",
   "metadata": {},
   "source": [
    "## Imports and data-reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6074cef-fa8f-4d97-a329-6688f440869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# !pip install cvxopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cvxopt import matrix, solvers\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a2f15-9e5d-4d03-a593-228e9a32e115",
   "metadata": {},
   "source": [
    "## Useful Functions for any part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c5dc98-0282-4b2d-a7e9-88c494ebd714",
   "metadata": {},
   "source": [
    "### For SVM/SVC plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd494fc1-02a2-46c7-80a4-f4c89cb13301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_it_all_rbf(train_X, train_y, test_X, test_y, reg_pam, ker_coeff_pam):\n",
    "\n",
    "    ######################################### 3D plot ########################################\n",
    "    Z = np.ones((len(reg_pam),len(ker_coeff_pam)))\n",
    "    W = np.ones((len(reg_pam),len(ker_coeff_pam)))\n",
    "    X, Y = np.meshgrid(reg_pam, ker_coeff_pam)\n",
    "\n",
    "\n",
    "    for idxc, c in enumerate(reg_pam):\n",
    "        for idxg, g in enumerate(ker_coeff_pam):\n",
    "            ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='poly', C = c, gamma = g))]\n",
    "            pipeline = Pipeline(ppl) \n",
    "            mod = pipeline\n",
    "#             mod = svm.SVC(kernel='poly', C = c, gamma = g)\n",
    "            mod.fit(train_X, np.ravel(train_y, order='C'))\n",
    "            Z[idxc][idxg] = mod.score(train_X, train_y)\n",
    "            W[idxc][idxg] = mod.score(test_X, test_y)\n",
    "\n",
    "    # print(X, Y, Z, W, X.shape, Y.shape, Z.shape, W.shape)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_wireframe(np.log10(X), np.log10(Y), Z, rstride=1, cstride=1, label='train', color='blue' )\n",
    "    ax.plot_wireframe(np.log10(X), np.log10(Y), W, rstride=1, cstride=1, label='test', color='red')\n",
    "    #ax.plot_surface(np.log10(X), np.log10(Y), Z, rstride=1, cstride=1, label='train', cmap='viridis', edgecolor='none' )\n",
    "    #ax.plot_surface(np.log10(X), np.log10(Y), W, rstride=1, cstride=1, label='test', cmap='viridis', edgecolor='none')\n",
    "    #ax.contour(np.log10(X), np.log10(Y), Z, label='train', cmap='viridis')\n",
    "    #ax.contour(np.log10(X), np.log10(Y), W, label='test', cmap='viridis')\n",
    "    #ax.colorbar()\n",
    "    ax.set_title('Poly kernel: C and Gamma Vs Accuracy')\n",
    "    ax.set_xlabel('log(C)')\n",
    "    ax.set_ylabel('log(Gamma)')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    ######################################## My conventional plots ########################################\n",
    "    for idxc, c in enumerate(reg_pam):\n",
    "        E_score_train = []\n",
    "        E_score_test = []\n",
    "\n",
    "        for idxg, g in enumerate(ker_coeff_pam):\n",
    "            ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='poly', C = c, gamma = g))]\n",
    "            pipeline = Pipeline(ppl) \n",
    "            mod = pipeline\n",
    "            #mod = svm.SVC(kernel='poly', C = c, gamma = g)\n",
    "            mod.fit(train_X, np.ravel(train_y, order='C'))\n",
    "            E_score_train.append(mod.score(train_X, train_y))\n",
    "            E_score_test.append(mod.score(test_X, test_y))\n",
    "\n",
    "        plt.plot(ker_coeff_pam, E_score_test, \"r-\", label=\"Test\")\n",
    "        plt.plot(ker_coeff_pam, E_score_train, \"b-\", label=\"Train\")\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel(r'$\\Gamma$')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        plt.title('Score for C=%s'%(c))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "def plot_it_all_linear(train_X, train_y, test_X, test_y, reg_pam):\n",
    "\n",
    "    ######################################## My conventional plots ########################################\n",
    "    E_score_train = []\n",
    "    E_score_test = []\n",
    "\n",
    "    for idxc, c in enumerate(reg_pam):    \n",
    "        ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='linear', C = c))]\n",
    "        pipeline = Pipeline(ppl) \n",
    "        mod = pipeline\n",
    "#         mod = svm.SVC(kernel='poly', C = c, gamma = g)\n",
    "        mod.fit(train_X, np.ravel(train_y, order='C'))\n",
    "        E_score_train.append(mod.score(train_X, train_y))\n",
    "        E_score_test.append(mod.score(test_X, test_y))\n",
    "\n",
    "    plt.plot(reg_pam, E_score_test, \"r-\", label=\"Test\")\n",
    "    plt.plot(reg_pam, E_score_train, \"b-\", label=\"Train\")\n",
    "    plt.title(\"Score Vs C for LIBSVM\")\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('C')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "#     plt.title('Score for C=%s'%(c))\n",
    "    plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "######################################## PLOTS FOR GRID SEARCH ########################################\n",
    "\n",
    "def plot_search_results(grid):\n",
    "    # Reference: https://stackoverflow.com/questions/37161563/how-to-graph-grid-scores-from-gridsearchcv\n",
    "    \"\"\"\n",
    "    Params: \n",
    "        grid: A trained GridSearchCV object.\n",
    "    For plotting the results when tuning several hyperparameters, \n",
    "    I fixed all parameters to their best value except for one and \n",
    "    plotted the mean score for the other parameter for each of its values.\n",
    "    \"\"\"\n",
    "    ## Results from grid search\n",
    "    results = grid.cv_results_\n",
    "    means_test = results['mean_test_score']\n",
    "    stds_test = results['std_test_score']\n",
    "    means_train = results['mean_train_score']\n",
    "    stds_train = results['std_train_score']\n",
    "\n",
    "    ## Getting indexes of values per hyper-parameter\n",
    "    masks=[]\n",
    "    masks_names= list(grid.best_params_.keys())\n",
    "    for p_k, p_v in grid.best_params_.items():\n",
    "        masks.append(list(results['param_'+p_k].data==p_v))\n",
    "\n",
    "    params=grid.param_grid\n",
    "\n",
    "    ## Ploting results\n",
    "    fig, ax = plt.subplots(1,len(params),sharex='none', sharey=False,figsize=(len(params)*10,len(params)*2.5))\n",
    "    fig.suptitle('Score per parameter')\n",
    "    fig.text(0.085, 0.5, 'MEAN SCORE', va='center', rotation='vertical')\n",
    "    pram_preformace_in_best = {}\n",
    "    for i, p in enumerate(masks_names):\n",
    "        m = np.stack(masks[:i] + masks[i+1:])\n",
    "#         m=np.array(masks[:i])\n",
    "        pram_preformace_in_best\n",
    "        best_parms_mask = m.all(axis=0)\n",
    "        best_index = np.where(best_parms_mask)[0]\n",
    "        x = np.array(params[p])\n",
    "        y_1 = np.array(means_test[best_index])\n",
    "        e_1 = np.array(stds_test[best_index])\n",
    "        y_2 = np.array(means_train[best_index])\n",
    "        e_2 = np.array(stds_train[best_index])\n",
    "        if (x[-1]>=x[-2]*9):\n",
    "            ax[i].set_xscale('log')\n",
    "        ax[i].errorbar(x, y_1, e_1, linestyle='--', marker='o', label='test')\n",
    "        ax[i].errorbar(x, y_2, e_2, linestyle='-', marker='^',label='train' )\n",
    "        ax[i].set_xlabel(p.upper())\n",
    "        ax[i].grid(True)\n",
    "        ax[i].legend()\n",
    "\n",
    "    #plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "def plot_search_results_linear(grid, reg_pam):\n",
    "    results = grid.cv_results_\n",
    "    means_test = results['mean_test_score']\n",
    "    stds_test = results['std_test_score']\n",
    "    means_train = results['mean_train_score']\n",
    "    stds_train = results['std_train_score']\n",
    "\n",
    "#     print(\"\")\n",
    "    # print('mean_test_score: ', means_test)\n",
    "    # print('std_test_score: ', stds_test)\n",
    "    # print('mean_train_score: ', means_train)\n",
    "    # print('std_train_score: ', stds_train)\n",
    "    x = reg_pam\n",
    "    y_1 = np.array(means_test)\n",
    "    e_1 = np.array(stds_test)\n",
    "    y_2 = np.array(means_train)\n",
    "    e_2 = np.array(stds_train)\n",
    "    plt.errorbar(x, y_1, e_1, linestyle='--', marker='o', label='test')\n",
    "    plt.errorbar(x, y_2, e_2, linestyle='-', marker='^',label='train' )\n",
    "    plt.grid(True)\n",
    "    plt.xscale('log')\n",
    "    plt.title('Score Vs C for CVXOPT')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('C')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af1107f-483f-4ba8-b0d7-fda77a06b0ab",
   "metadata": {},
   "source": [
    "### For CVXOPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b1931d-8e9a-46d5-9acf-7bee17e42566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://courses.csail.mit.edu/6.867/wiki/images/a/a7/Qp-cvxopt.pdf\n",
    "# Reference: https://www.robots.ox.ac.uk/~az/lectures/ml/lect3.pdf\n",
    "\n",
    "def cvx_try(X, y, X_test, y_test, which, C=1.0, gamma=0.04, coef0= 0.0, degree=3, threshold=1e-4):\n",
    "    \n",
    "    # Linear: C\n",
    "    # Poly: C, Gamma, Degree, Coef0\n",
    "    # Sigmoid: C, Gamma, Coef0\n",
    "    # RBF: C, gamma\n",
    "    \n",
    "    def makeHP(X1, X2, y_temp, which):\n",
    "        H = np.dot(X1, X2.T)\n",
    "        if (which=='linear'):\n",
    "            P = matrix(y_temp.dot(y_temp.T)*H)\n",
    "        elif (which=='poly'):\n",
    "            H = (gamma*H+coef0)**degree\n",
    "            P = matrix(y_temp.dot(y_temp.T)*H)\n",
    "        elif (which=='sigmoid'):\n",
    "            H = np.tanh(gamma*H+coef0)\n",
    "            P = matrix(y_temp.dot(y_temp.T)*H)\n",
    "        elif (which=='rbf'):\n",
    "            H1 = np.diag(X1.dot(X1.T)).reshape(-1, 1)*np.ones((1, X2.shape[0]))\n",
    "            H2 = np.diag(X2.dot(X2.T)).reshape(1, -1)*np.ones((X1.shape[0],1))\n",
    "            H = 2*H-H1-H2\n",
    "            H = np.exp(gamma*H)\n",
    "            P = matrix(y_temp.dot(y_temp.T)*H)\n",
    "    \n",
    "        return H,P\n",
    "    \n",
    "    y_temp = y.reshape(-1, 1)*1.\n",
    "    H,P = makeHP(X, X, y_temp, which)\n",
    "    q = matrix(-np.ones((X.shape[0], 1)))\n",
    "    A = matrix(y_temp.reshape(1, -1))\n",
    "    b = matrix(np.zeros(1))\n",
    "    G = matrix(np.r_[-1*(np.eye(X.shape[0])), np.eye(X.shape[0])])\n",
    "    h = matrix(np.r_[np.zeros(X.shape[0]), np.ones(X.shape[0])*C])\n",
    "    #print(repr(q),repr(A),repr(b),repr(G),repr(h))\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol = solvers.qp(P,q,G,h,A,b)\n",
    "    lambs, _ = np.array(sol['x']), np.array(sol['primal objective'])\n",
    "    \n",
    "    \n",
    "    ########## GET SUPPORT VECTORS ################\n",
    "    idx = np.where(lambs > threshold)[0] # Indices of support vectors\n",
    "    #Extract support vectors\n",
    "    sX = X[idx,:]\n",
    "    sy = y[idx]\n",
    "    lambs = lambs[idx]\n",
    "    b = np.sum(sy)\n",
    "    for j in idx:\n",
    "        b = b - np.sum(lambs*sy*(H[j, idx].reshape(-1, 1)))\n",
    "    b /= idx.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ######### PREDICT ###########\n",
    "    ynew = np.zeros((X_test.shape[0],))\n",
    "    Htemp,_ = makeHP(sX, test_X, ynew, which)\n",
    "    rightcnt = 0.\n",
    "#     print(ynew.shape, Htemp.shape)\n",
    "    for i in range(ynew.shape[0]):\n",
    "        ynew[i] = np.sum(lambs*sy*Htemp[:,i].reshape(-1,1))+b\n",
    "        if (ynew[i]*y_test[i]>0):\n",
    "            rightcnt+=1.\n",
    "    y_pred = np.sign(ynew)\n",
    "    score = rightcnt*100.0/ynew.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return lambs, sX, sy, y_pred, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7eb38-91e1-4a7c-b926-285c2785479a",
   "metadata": {},
   "source": [
    "# Part 1A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bfee0a-0780-4513-a87a-0e41e4f5e6bf",
   "metadata": {},
   "source": [
    "### CVX something and warnings filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2428bd38-316c-4ef0-a670-760148f7d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cvx_try(X, y, X_test, y_test, which, C=1.0, gamma=0.04, coef0= 0.0, degree=3, threshold=1e-4):\n",
    "# legr, suppX, suppy, test_pred, acc = cvx_try(train_X, train_y, test_X, test_y, which='poly', C=0.01, gamma=1000, degree=1)\n",
    "\n",
    "\n",
    "# # threshold = 1e-4\n",
    "# # ############ https://xavierbourretsicotte.github.io/SVM_implementation.html #########\n",
    "# # #w parameter in vectorized form\n",
    "# # w = ((train_y * idk).T @ train_X).reshape(-1,1)\n",
    "# # #Selecting the set of indices S corresponding to non zero parameters\n",
    "# # S = (idk > threshold).flatten()\n",
    "# # #Computing b\n",
    "# # b = train_y[S] - np.dot(train_X[S], w)\n",
    "# # #Display results\n",
    "# # # print('Alphas = ',idk[idk > threshold])\n",
    "# # print('w = ', w.flatten())\n",
    "# # print('b = ', b[0])\n",
    "\n",
    "# # suppV = (suppX, suppy)\n",
    "# # print(\"Support vectors: \", suppV)\n",
    "# print(\"Support vectors: \", sorted(suppX, key=lambda x: x[0]))\n",
    "# print(\"CVX score: \", acc)\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)\n",
    "# warnings.resetwarnings()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81960f5-7fbd-411c-a622-ab39e56ce844",
   "metadata": {},
   "source": [
    "# DEATH BY PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f36be-2e1e-499e-b79a-9c574b71338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '2019EE10143.csv'\n",
    "random_state = 69420\n",
    "# split_frac = 0.8\n",
    "# low_reg, high_reg = -3,2\n",
    "# low_cof, high_cof = -3,1\n",
    "# low_deg, high_deg = 1,4\n",
    "split_frac = 0.1\n",
    "low_reg, high_reg = -1,1\n",
    "low_cof, high_cof = -1,1\n",
    "low_deg, high_deg = 1,2\n",
    "\n",
    "reg_pam = np.logspace(low_reg, high_reg, num=1+high_reg-low_reg)\n",
    "ker_coeff_pam = np.logspace(low_cof, high_cof, num=1+high_cof-low_cof)\n",
    "deg_pam = np.linspace(low_deg, high_deg, 1+high_deg-low_deg)\n",
    "\n",
    "\n",
    "df = pd.read_csv(file_name, header=None)\n",
    "pairs = [(0,1), (4,6), (8,9)]\n",
    "# pairs = [(8,9)]\n",
    "features = [10,25]\n",
    "typ = ['linear','poly','rbf','sigmoid']\n",
    "for (lab1, lab2) in pairs:\n",
    "    for num_ft in features:\n",
    "        for which in typ:\n",
    "            print(\"#################################################################################\")\n",
    "            print(\"Labels:\",lab1, \",\", lab2)\n",
    "            print(\"Number of features:\", num_ft)\n",
    "            print(\"#################################################################################\")\n",
    "\n",
    "            #CONVERT TO USE\n",
    "            df_temp = df.loc[df[25].isin([lab1, lab2])]\n",
    "            #print(len(df_temp))\n",
    "            df_temp.iloc[df_temp[25] == lab1, 25] = -1\n",
    "            df_temp.iloc[df_temp[25] == lab2, 25] = 1\n",
    "            df_temp = df_temp.sample(frac=1., random_state=random_state)\n",
    "\n",
    "            # SPLIT IN TRAIN AND TEST\n",
    "            train_df = df_temp[:int(split_frac*len(df_temp))]\n",
    "            test_df = df_temp[int(split_frac*len(df_temp)):]\n",
    "\n",
    "            # SPLIT BY FEATURES\n",
    "            X_train_temp = train_df.loc[:, [i for i in range(num_ft)]]\n",
    "            y_train_temp = train_df.loc[:, [25]]\n",
    "            X_test_temp = test_df.loc[:, [i for i in range(num_ft)]]\n",
    "            y_test_temp = test_df.loc[:, [25]]\n",
    "\n",
    "\n",
    "\n",
    "            train_X = np.array(X_train_temp.values)\n",
    "            train_y = np.array(y_train_temp.values)\n",
    "            test_X = np.array(X_test_temp.values)\n",
    "            test_y = np.array(y_test_temp.values)\n",
    "\n",
    "            print (\"Number of training examples:\", train_X.shape, train_y.shape)\n",
    "            print (\"Number of test examples:\", test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "            # SVM STUFF & GRID SEARCH CV\n",
    "            print(\"--------------------------LIBSVM for {ty}-----------------------------\".format(ty=which.upper()))\n",
    "            \n",
    "            if (which=='linear'):\n",
    "                ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='linear'))]\n",
    "                parameters = {'SVM__C':reg_pam} #Linear\n",
    "            elif (which=='rbf' or which=='sigmoid'):\n",
    "                ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel=which))]\n",
    "                parameters = {'SVM__C':reg_pam, 'SVM__gamma':ker_coeff_pam} #RBF/SIGMOID\n",
    "            elif (which=='poly'):\n",
    "                ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='poly'))]\n",
    "                parameters = {'SVM__C':reg_pam, 'SVM__degree':deg_pam, 'SVM__gamma':ker_coeff_pam} #Poly\n",
    "            \n",
    "            pipeline = Pipeline(ppl) \n",
    "            #parameters = {'SVM__C':reg_pam} #Linear\n",
    "            #parameters = {'SVM__C':reg_pam, 'SVM__degree':deg_pam, 'SVM__gamma':ker_coeff_pam} #Poly\n",
    "            #parameters = {'SVM__C':reg_pam, 'SVM__degree':deg_pam, 'SVM__gamma':ker_coeff_pam}\n",
    "            grid = GridSearchCV(pipeline, param_grid=parameters, cv=5, return_train_score=True, verbose=0)\n",
    "\n",
    "            grid.fit(train_X, np.ravel(train_y, order='C'))\n",
    "            #print(grid.score(train_X, train_y))\n",
    "            #print(grid.score(test_X, test_y))\n",
    "            bestpar = grid.best_params_\n",
    "            print(\"The Best parameters according to grid search are:\", bestpar)\n",
    "            \n",
    "            \n",
    "            if (which=='linear'):\n",
    "                mod = svm.SVC(kernel='linear', C = bestpar['SVM__C']) #Linear\n",
    "            elif (which=='rbf' or which=='sigmoid'):\n",
    "                mod = svm.SVC(kernel=which, C = bestpar['SVM__C'], gamma = bestpar['SVM__gamma']) #RBF/SIGMOID\n",
    "            elif (which=='poly'):\n",
    "                mod = svm.SVC(kernel='poly', C = bestpar['SVM__C'], gamma = bestpar['SVM__gamma'], degree= bestpar['SVM__degree']) #Poly\n",
    "\n",
    "\n",
    "            mod.fit(train_X, np.ravel(train_y, order='C'))\n",
    "            print(\"Training score for LIBSVM with best parameters:\", 100*mod.score(train_X, train_y), \"%\")\n",
    "            print(\"Test score for LIBSVM with best parameters:\", 100*mod.score(test_X, test_y), \"%\")\n",
    "            ab,a_ind,b_ind=np.intersect1d(train_X, mod.support_vectors_, return_indices=True)\n",
    "            a_ind = sorted(a_ind)\n",
    "            boi = []\n",
    "            for i in range(0, len(a_ind), num_ft):\n",
    "                boi.append(a_ind[i]//num_ft)\n",
    "            \n",
    "            print(\"Indices of support vectors as returned by LIBSVM: \", boi)\n",
    "            \n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "\n",
    "            # CVXOPT STUFF\n",
    "            print(\"--------------------------CVXOPT for {ty}-----------------------------\".format(ty=which.upper()))\n",
    "            \n",
    "            flag=True\n",
    "            if (which=='linear'):\n",
    "                legr, suppX, suppy, test_pred, acc = cvx_try(train_X, train_y, test_X, test_y, which='linear', C=bestpar['SVM__C']) #Linear\n",
    "            elif (which=='rbf' or which=='sigmoid'):\n",
    "                try:\n",
    "                    legr, suppX, suppy, test_pred, acc = cvx_try(train_X, train_y, test_X, test_y, which=which, C=bestpar['SVM__C'], gamma = bestpar['SVM__gamma']) #RBF/Sigmoid\n",
    "                except:\n",
    "                    flag=False\n",
    "                    print(\"An exception occurred for {ty} at params C={c}, gamma={gam}\".format(ty=which.title(), c=bestpar['SVM__C'], gam=bestpar['SVM__gamma']))\n",
    "            elif (which=='poly'):\n",
    "                legr, suppX, suppy, test_pred, acc = cvx_try(train_X, train_y, test_X, test_y, which='poly', C=bestpar['SVM__C'], gamma = bestpar['SVM__gamma'], degree= bestpar['SVM__degree']) #Poly\n",
    "\n",
    "            if (flag==True):\n",
    "                print(\"Test score for CVXOPT with best parameters:\", acc, \"%\")\n",
    "                ab,a_ind,b_ind=np.intersect1d(train_X, suppX, return_indices=True)\n",
    "                a_ind = sorted(a_ind)\n",
    "                boi = []\n",
    "                for i in range(0, len(a_ind), num_ft):\n",
    "                    boi.append(a_ind[i]//num_ft)\n",
    "                print(\"Indices of support vectors as returned by CVXOPT: \", boi)\n",
    "            \n",
    "\n",
    "\n",
    "            # PLOTTINGS\n",
    "            if (which=='linear'):\n",
    "                plot_it_all_linear(train_X, train_y, test_X, test_y, reg_pam) #Linear. Nothing for anything else. Can use other one for RBF\n",
    "                plot_search_results_linear(grid, reg_pam) #Linear\n",
    "            else:\n",
    "                plot_search_results(grid) #For non-linear or any with multiple parameters\n",
    "\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42fa35-81b4-4a5d-b608-c37707509d23",
   "metadata": {},
   "source": [
    "# PART 1A (Multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8049850-4efa-4442-af5f-091074224984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "Number of features: 10\n",
      "#####################################################################\n",
      "Number of training examples: (2400, 10) (2400, 1)\n",
      "Number of test examples: (600, 10) (600, 1)\n",
      "--------------------------LIBSVM for LINEAR for 10 features-----------------------------\n"
     ]
    }
   ],
   "source": [
    "file_name = '2019EE10143.csv'\n",
    "random_state = 69420\n",
    "split_frac = 0.8\n",
    "low_reg, high_reg = -2,2\n",
    "low_cof, high_cof = -3,1\n",
    "low_deg, high_deg = 1,4\n",
    "# split_frac = 0.1\n",
    "# low_reg, high_reg = -1,1\n",
    "# low_cof, high_cof = -1,1\n",
    "# low_deg, high_deg = 1,2\n",
    "\n",
    "reg_pam = np.logspace(low_reg, high_reg, num=1+high_reg-low_reg)\n",
    "ker_coeff_pam = np.logspace(low_cof, high_cof, num=1+high_cof-low_cof)\n",
    "deg_pam = np.linspace(low_deg, high_deg, 1+high_deg-low_deg)\n",
    "\n",
    "df = pd.read_csv(file_name, header=None)\n",
    "\n",
    "features = [10,25]\n",
    "typ = ['linear','poly','rbf','sigmoid']\n",
    "for num_ft in features:\n",
    "    for which in typ:\n",
    "        print(\"#####################################################################\")\n",
    "        print(\"Number of features:\", num_ft)\n",
    "        print(\"#####################################################################\")\n",
    "\n",
    "        #CONVERT TO USE\n",
    "        # df_temp = df.loc[df[25].isin([lab1, lab2])]\n",
    "        # print(len(df_temp))\n",
    "        # df_temp.iloc[df_temp[25] == lab1, 25] = -1\n",
    "        # df_temp.iloc[df_temp[25] == lab2, 25] = 1\n",
    "        df_temp = df.sample(frac=1., random_state=random_state)\n",
    "\n",
    "        # SPLIT IN TRAIN AND TEST\n",
    "        train_df = df_temp[:int(split_frac*len(df_temp))]\n",
    "        test_df = df_temp[int(split_frac*len(df_temp)):]\n",
    "\n",
    "        # SPLIT BY FEATURES\n",
    "        X_train_temp = train_df.loc[:, [i for i in range(num_ft)]]\n",
    "        y_train_temp = train_df.loc[:, [25]]\n",
    "        X_test_temp = test_df.loc[:, [i for i in range(num_ft)]]\n",
    "        y_test_temp = test_df.loc[:, [25]]\n",
    "\n",
    "\n",
    "\n",
    "        train_X = np.array(X_train_temp.values)\n",
    "        train_y = np.array(y_train_temp.values)\n",
    "        test_X = np.array(X_test_temp.values)\n",
    "        test_y = np.array(y_test_temp.values)\n",
    "\n",
    "        print (\"Number of training examples:\", train_X.shape, train_y.shape)\n",
    "        print (\"Number of test examples:\", test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "        # SVM STUFF & GRID SEARCH CV\n",
    "        print(\"--------------------------LIBSVM for {ty} for {ft} features-----------------------------\".format(ty=which.upper(), ft=num_ft))\n",
    "\n",
    "        if (which=='linear'):\n",
    "            ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='linear'))]\n",
    "            parameters = {'SVM__C':reg_pam} #Linear\n",
    "        elif (which=='rbf' or which=='sigmoid'):\n",
    "            ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel=which))]\n",
    "            parameters = {'SVM__C':reg_pam, 'SVM__gamma':ker_coeff_pam} #RBF/SIGMOID\n",
    "        elif (which=='poly'):\n",
    "            ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='poly'))]\n",
    "            parameters = {'SVM__C':reg_pam, 'SVM__degree':deg_pam, 'SVM__gamma':ker_coeff_pam} #Poly\n",
    "\n",
    "        pipeline = Pipeline(ppl) \n",
    "        #parameters = {'SVM__C':reg_pam} #Linear\n",
    "        #parameters = {'SVM__C':reg_pam, 'SVM__degree':deg_pam, 'SVM__gamma':ker_coeff_pam} #Poly\n",
    "        #parameters = {'SVM__C':reg_pam, 'SVM__degree':deg_pam, 'SVM__gamma':ker_coeff_pam}\n",
    "        grid = GridSearchCV(pipeline, param_grid=parameters, cv=5, return_train_score=True, verbose=0)\n",
    "\n",
    "        grid.fit(train_X, np.ravel(train_y, order='C'))\n",
    "        bestpar = grid.best_params_\n",
    "        print(\"The Best parameters according to grid search are:\", bestpar)\n",
    "        print(\"Best training score from grid search pipeline:\",100*grid.score(train_X, train_y), \"%\")\n",
    "        print(\"Best test score from grid search pipeline:\",100*grid.score(test_X, test_y), \"%\")\n",
    "        \n",
    "\n",
    "        if (which=='linear'):\n",
    "            mod = svm.SVC(kernel='linear', C = bestpar['SVM__C']) #Linear\n",
    "        elif (which=='rbf' or which=='sigmoid'):\n",
    "            mod = svm.SVC(kernel=which, C = bestpar['SVM__C'], gamma = bestpar['SVM__gamma']) #RBF/SIGMOID\n",
    "        elif (which=='poly'):\n",
    "            mod = svm.SVC(kernel='poly', C = bestpar['SVM__C'], gamma = bestpar['SVM__gamma'], degree= bestpar['SVM__degree']) #Poly\n",
    "\n",
    "\n",
    "        mod.fit(train_X, np.ravel(train_y, order='C'))\n",
    "        print(\"Training score for LIBSVM with best parameters:\", 100*mod.score(train_X, train_y), \"%\")\n",
    "        print(\"Test score for LIBSVM with best parameters:\", 100*mod.score(test_X, test_y), \"%\")\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "        # PLOTTINGS\n",
    "        if (which=='linear'):\n",
    "            plot_it_all_linear(train_X, train_y, test_X, test_y, reg_pam) #Linear. Nothing for anything else. Can use other one for RBF\n",
    "            plot_search_results_linear(grid, reg_pam) #Linear\n",
    "        else:\n",
    "            plot_search_results(grid) #For non-linear or any with multiple parameters\n",
    "\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96795ff7-f61b-414e-bf56-7e16ffeb1b2c",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05706226-3bc6-473c-8c98-7d099cfa45b9",
   "metadata": {},
   "source": [
    "### Saving in desirable format (Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fdb9e0b-cf9b-48f6-8bd1-08748ef1c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save2csv(filename, Y_pred):\n",
    "    with open(filename, 'w+') as f:\n",
    "        f.write('Id,Class\\n')\n",
    "        for i in range(Y_pred.shape[0]):\n",
    "            if i+1<1000:\n",
    "                f.write('{},{:d}\\n'.format(str(i+1), int(Y_pred[i])))\n",
    "            else:\n",
    "                f.write('\\\"{:01d},{:03d}\\\",{:d}\\n'.format((i+1)//1000, (i+1)%1000, int(Y_pred[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4cb3d5-d0a8-49a5-b0a5-453950936673",
   "metadata": {},
   "source": [
    "## Basic Hyperparameter sweep over everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff256a7c-8e9a-4e2a-9dc6-35403c544178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################################\n",
      "Number of features: 25\n",
      "#################################################################################\n",
      "Number of training examples: (7200, 25) (7200, 1)\n",
      "Number of test examples: (800, 25) (800, 1)\n",
      "--------------------------LIBSVM for RBF-----------------------------\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "[CV 1/5] END SVM__C=0.001, SVM__gamma=0.001;, score=(train=0.115, test=0.115) total time=   5.9s\n",
      "[CV 2/5] END SVM__C=0.001, SVM__gamma=0.001;, score=(train=0.115, test=0.115) total time=   6.4s\n",
      "[CV 3/5] END SVM__C=0.001, SVM__gamma=0.001;, score=(train=0.115, test=0.115) total time=   7.2s\n",
      "[CV 4/5] END SVM__C=0.001, SVM__gamma=0.001;, score=(train=0.115, test=0.115) total time=   6.0s\n",
      "[CV 5/5] END SVM__C=0.001, SVM__gamma=0.001;, score=(train=0.115, test=0.115) total time=   7.5s\n",
      "[CV 1/5] END SVM__C=0.001, SVM__gamma=0.01;, score=(train=0.115, test=0.115) total time=   6.0s\n",
      "[CV 2/5] END SVM__C=0.001, SVM__gamma=0.01;, score=(train=0.115, test=0.115) total time=   6.2s\n",
      "[CV 3/5] END SVM__C=0.001, SVM__gamma=0.01;, score=(train=0.115, test=0.115) total time=   5.4s\n",
      "[CV 4/5] END SVM__C=0.001, SVM__gamma=0.01;, score=(train=0.115, test=0.115) total time=   5.1s\n",
      "[CV 5/5] END SVM__C=0.001, SVM__gamma=0.01;, score=(train=0.115, test=0.115) total time=   5.6s\n",
      "[CV 1/5] END SVM__C=0.001, SVM__gamma=0.1;, score=(train=0.115, test=0.115) total time=   5.4s\n",
      "[CV 2/5] END SVM__C=0.001, SVM__gamma=0.1;, score=(train=0.115, test=0.115) total time=   5.3s\n",
      "[CV 3/5] END SVM__C=0.001, SVM__gamma=0.1;, score=(train=0.115, test=0.115) total time=   5.0s\n",
      "[CV 4/5] END SVM__C=0.001, SVM__gamma=0.1;, score=(train=0.115, test=0.115) total time=   5.2s\n",
      "[CV 5/5] END SVM__C=0.001, SVM__gamma=0.1;, score=(train=0.115, test=0.115) total time=   5.2s\n",
      "[CV 1/5] END SVM__C=0.001, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   6.2s\n",
      "[CV 2/5] END SVM__C=0.001, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   5.1s\n",
      "[CV 3/5] END SVM__C=0.001, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   5.1s\n",
      "[CV 4/5] END SVM__C=0.001, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   5.2s\n",
      "[CV 5/5] END SVM__C=0.001, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   5.1s\n",
      "[CV 1/5] END SVM__C=0.001, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   5.7s\n",
      "[CV 2/5] END SVM__C=0.001, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   5.8s\n",
      "[CV 3/5] END SVM__C=0.001, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   7.7s\n",
      "[CV 4/5] END SVM__C=0.001, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   6.2s\n",
      "[CV 5/5] END SVM__C=0.001, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   6.3s\n",
      "[CV 1/5] END SVM__C=0.001, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=  11.3s\n",
      "[CV 2/5] END SVM__C=0.001, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=  10.8s\n",
      "[CV 3/5] END SVM__C=0.001, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=  10.1s\n",
      "[CV 4/5] END SVM__C=0.001, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=  12.9s\n",
      "[CV 5/5] END SVM__C=0.001, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=   9.5s\n",
      "[CV 1/5] END SVM__C=0.001, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=  11.1s\n",
      "[CV 2/5] END SVM__C=0.001, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=   9.5s\n",
      "[CV 3/5] END SVM__C=0.001, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=  10.0s\n",
      "[CV 4/5] END SVM__C=0.001, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=   9.9s\n",
      "[CV 5/5] END SVM__C=0.001, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=   9.2s\n",
      "[CV 1/5] END SVM__C=0.01, SVM__gamma=0.001;, score=(train=0.115, test=0.115) total time=   5.3s\n",
      "[CV 2/5] END SVM__C=0.01, SVM__gamma=0.001;, score=(train=0.115, test=0.115) total time=   5.1s\n",
      "[CV 3/5] END SVM__C=0.01, SVM__gamma=0.001;, score=(train=0.115, test=0.115) total time=   5.9s\n",
      "[CV 4/5] END SVM__C=0.01, SVM__gamma=0.001;, score=(train=0.115, test=0.115) total time=   5.9s\n",
      "[CV 5/5] END SVM__C=0.01, SVM__gamma=0.001;, score=(train=0.115, test=0.115) total time=   5.3s\n",
      "[CV 1/5] END SVM__C=0.01, SVM__gamma=0.01;, score=(train=0.313, test=0.308) total time=   5.1s\n",
      "[CV 2/5] END SVM__C=0.01, SVM__gamma=0.01;, score=(train=0.317, test=0.310) total time=   6.0s\n",
      "[CV 3/5] END SVM__C=0.01, SVM__gamma=0.01;, score=(train=0.314, test=0.308) total time=   5.9s\n",
      "[CV 4/5] END SVM__C=0.01, SVM__gamma=0.01;, score=(train=0.319, test=0.317) total time=   5.7s\n",
      "[CV 5/5] END SVM__C=0.01, SVM__gamma=0.01;, score=(train=0.313, test=0.313) total time=   5.2s\n",
      "[CV 1/5] END SVM__C=0.01, SVM__gamma=0.1;, score=(train=0.206, test=0.203) total time=   6.3s\n",
      "[CV 2/5] END SVM__C=0.01, SVM__gamma=0.1;, score=(train=0.208, test=0.209) total time=   5.2s\n",
      "[CV 3/5] END SVM__C=0.01, SVM__gamma=0.1;, score=(train=0.210, test=0.213) total time=   5.9s\n",
      "[CV 4/5] END SVM__C=0.01, SVM__gamma=0.1;, score=(train=0.207, test=0.204) total time=   5.1s\n",
      "[CV 5/5] END SVM__C=0.01, SVM__gamma=0.1;, score=(train=0.208, test=0.207) total time=   5.7s\n",
      "[CV 1/5] END SVM__C=0.01, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   6.6s\n",
      "[CV 2/5] END SVM__C=0.01, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   6.4s\n",
      "[CV 3/5] END SVM__C=0.01, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   6.3s\n",
      "[CV 4/5] END SVM__C=0.01, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   5.4s\n",
      "[CV 5/5] END SVM__C=0.01, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   5.4s\n",
      "[CV 1/5] END SVM__C=0.01, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   7.1s\n",
      "[CV 2/5] END SVM__C=0.01, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   7.0s\n",
      "[CV 3/5] END SVM__C=0.01, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   6.9s\n",
      "[CV 4/5] END SVM__C=0.01, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   6.3s\n",
      "[CV 5/5] END SVM__C=0.01, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   6.5s\n",
      "[CV 1/5] END SVM__C=0.01, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=   9.4s\n",
      "[CV 2/5] END SVM__C=0.01, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=  10.5s\n",
      "[CV 3/5] END SVM__C=0.01, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=  10.1s\n",
      "[CV 4/5] END SVM__C=0.01, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=   9.9s\n",
      "[CV 5/5] END SVM__C=0.01, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=  10.0s\n",
      "[CV 1/5] END SVM__C=0.01, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=  10.1s\n",
      "[CV 2/5] END SVM__C=0.01, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=   9.7s\n",
      "[CV 3/5] END SVM__C=0.01, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=  11.1s\n",
      "[CV 4/5] END SVM__C=0.01, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=  10.8s\n",
      "[CV 5/5] END SVM__C=0.01, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=  10.3s\n",
      "[CV 1/5] END SVM__C=0.1, SVM__gamma=0.001;, score=(train=0.650, test=0.664) total time=   5.1s\n",
      "[CV 2/5] END SVM__C=0.1, SVM__gamma=0.001;, score=(train=0.660, test=0.631) total time=   4.9s\n",
      "[CV 3/5] END SVM__C=0.1, SVM__gamma=0.001;, score=(train=0.642, test=0.628) total time=   4.9s\n",
      "[CV 4/5] END SVM__C=0.1, SVM__gamma=0.001;, score=(train=0.652, test=0.654) total time=   5.1s\n",
      "[CV 5/5] END SVM__C=0.1, SVM__gamma=0.001;, score=(train=0.650, test=0.650) total time=   4.9s\n",
      "[CV 1/5] END SVM__C=0.1, SVM__gamma=0.01;, score=(train=0.901, test=0.914) total time=   2.8s\n",
      "[CV 2/5] END SVM__C=0.1, SVM__gamma=0.01;, score=(train=0.905, test=0.891) total time=   2.7s\n",
      "[CV 3/5] END SVM__C=0.1, SVM__gamma=0.01;, score=(train=0.905, test=0.899) total time=   3.1s\n",
      "[CV 4/5] END SVM__C=0.1, SVM__gamma=0.01;, score=(train=0.908, test=0.889) total time=   2.7s\n",
      "[CV 5/5] END SVM__C=0.1, SVM__gamma=0.01;, score=(train=0.901, test=0.903) total time=   2.7s\n",
      "[CV 1/5] END SVM__C=0.1, SVM__gamma=0.1;, score=(train=0.940, test=0.925) total time=   3.5s\n",
      "[CV 2/5] END SVM__C=0.1, SVM__gamma=0.1;, score=(train=0.947, test=0.908) total time=   3.5s\n",
      "[CV 3/5] END SVM__C=0.1, SVM__gamma=0.1;, score=(train=0.943, test=0.921) total time=   3.5s\n",
      "[CV 4/5] END SVM__C=0.1, SVM__gamma=0.1;, score=(train=0.945, test=0.904) total time=   3.5s\n",
      "[CV 5/5] END SVM__C=0.1, SVM__gamma=0.1;, score=(train=0.940, test=0.914) total time=   3.5s\n",
      "[CV 1/5] END SVM__C=0.1, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   5.3s\n",
      "[CV 2/5] END SVM__C=0.1, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   6.1s\n",
      "[CV 3/5] END SVM__C=0.1, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   6.0s\n",
      "[CV 4/5] END SVM__C=0.1, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   6.9s\n",
      "[CV 5/5] END SVM__C=0.1, SVM__gamma=1.0;, score=(train=0.115, test=0.115) total time=   6.5s\n",
      "[CV 1/5] END SVM__C=0.1, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   6.7s\n",
      "[CV 2/5] END SVM__C=0.1, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   9.9s\n",
      "[CV 3/5] END SVM__C=0.1, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   7.5s\n",
      "[CV 4/5] END SVM__C=0.1, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   6.3s\n",
      "[CV 5/5] END SVM__C=0.1, SVM__gamma=10.0;, score=(train=0.115, test=0.115) total time=   7.7s\n",
      "[CV 1/5] END SVM__C=0.1, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=  12.1s\n",
      "[CV 2/5] END SVM__C=0.1, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=   9.9s\n",
      "[CV 3/5] END SVM__C=0.1, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=  11.7s\n",
      "[CV 4/5] END SVM__C=0.1, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=   9.0s\n",
      "[CV 5/5] END SVM__C=0.1, SVM__gamma=100.0;, score=(train=0.115, test=0.115) total time=   9.6s\n",
      "[CV 1/5] END SVM__C=0.1, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=   9.1s\n",
      "[CV 2/5] END SVM__C=0.1, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=   8.9s\n",
      "[CV 3/5] END SVM__C=0.1, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=   8.8s\n",
      "[CV 4/5] END SVM__C=0.1, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=   9.0s\n",
      "[CV 5/5] END SVM__C=0.1, SVM__gamma=1000.0;, score=(train=0.115, test=0.115) total time=   8.9s\n",
      "[CV 1/5] END SVM__C=1.0, SVM__gamma=0.001;, score=(train=0.888, test=0.899) total time=   2.5s\n",
      "[CV 2/5] END SVM__C=1.0, SVM__gamma=0.001;, score=(train=0.893, test=0.879) total time=   2.5s\n",
      "[CV 3/5] END SVM__C=1.0, SVM__gamma=0.001;, score=(train=0.891, test=0.883) total time=   2.5s\n",
      "[CV 4/5] END SVM__C=1.0, SVM__gamma=0.001;, score=(train=0.895, test=0.876) total time=   2.5s\n",
      "[CV 5/5] END SVM__C=1.0, SVM__gamma=0.001;, score=(train=0.888, test=0.888) total time=   2.5s\n",
      "[CV 1/5] END SVM__C=1.0, SVM__gamma=0.01;, score=(train=0.947, test=0.951) total time=   1.2s\n",
      "[CV 2/5] END SVM__C=1.0, SVM__gamma=0.01;, score=(train=0.951, test=0.927) total time=   1.2s\n",
      "[CV 3/5] END SVM__C=1.0, SVM__gamma=0.01;, score=(train=0.948, test=0.940) total time=   1.2s\n",
      "[CV 4/5] END SVM__C=1.0, SVM__gamma=0.01;, score=(train=0.953, test=0.926) total time=   1.2s\n",
      "[CV 5/5] END SVM__C=1.0, SVM__gamma=0.01;, score=(train=0.948, test=0.937) total time=   1.2s\n",
      "[CV 1/5] END SVM__C=1.0, SVM__gamma=0.1;, score=(train=0.998, test=0.976) total time=   2.7s\n",
      "[CV 2/5] END SVM__C=1.0, SVM__gamma=0.1;, score=(train=0.997, test=0.963) total time=   2.7s\n",
      "[CV 3/5] END SVM__C=1.0, SVM__gamma=0.1;, score=(train=0.998, test=0.967) total time=   2.8s\n",
      "[CV 4/5] END SVM__C=1.0, SVM__gamma=0.1;, score=(train=0.998, test=0.956) total time=   2.8s\n",
      "[CV 5/5] END SVM__C=1.0, SVM__gamma=0.1;, score=(train=0.998, test=0.967) total time=   2.9s\n",
      "[CV 1/5] END SVM__C=1.0, SVM__gamma=1.0;, score=(train=1.000, test=0.258) total time=   5.8s\n",
      "[CV 2/5] END SVM__C=1.0, SVM__gamma=1.0;, score=(train=1.000, test=0.248) total time=   5.7s\n",
      "[CV 3/5] END SVM__C=1.0, SVM__gamma=1.0;, score=(train=1.000, test=0.244) total time=   6.2s\n",
      "[CV 4/5] END SVM__C=1.0, SVM__gamma=1.0;, score=(train=1.000, test=0.251) total time=   6.1s\n",
      "[CV 5/5] END SVM__C=1.0, SVM__gamma=1.0;, score=(train=1.000, test=0.247) total time=   5.7s\n",
      "[CV 1/5] END SVM__C=1.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   6.1s\n",
      "[CV 2/5] END SVM__C=1.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   6.1s\n",
      "[CV 3/5] END SVM__C=1.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.3s\n",
      "[CV 4/5] END SVM__C=1.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   6.8s\n",
      "[CV 5/5] END SVM__C=1.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   6.9s\n",
      "[CV 1/5] END SVM__C=1.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=   9.8s\n",
      "[CV 2/5] END SVM__C=1.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  10.7s\n",
      "[CV 3/5] END SVM__C=1.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  12.0s\n",
      "[CV 4/5] END SVM__C=1.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  10.2s\n",
      "[CV 5/5] END SVM__C=1.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=   9.2s\n",
      "[CV 1/5] END SVM__C=1.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=   9.8s\n",
      "[CV 2/5] END SVM__C=1.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.1s\n",
      "[CV 3/5] END SVM__C=1.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  11.0s\n",
      "[CV 4/5] END SVM__C=1.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.1s\n",
      "[CV 5/5] END SVM__C=1.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=   9.9s\n",
      "[CV 1/5] END SVM__C=10.0, SVM__gamma=0.001;, score=(train=0.922, test=0.926) total time=   1.2s\n",
      "[CV 2/5] END SVM__C=10.0, SVM__gamma=0.001;, score=(train=0.925, test=0.908) total time=   2.1s\n",
      "[CV 3/5] END SVM__C=10.0, SVM__gamma=0.001;, score=(train=0.923, test=0.916) total time=   1.2s\n",
      "[CV 4/5] END SVM__C=10.0, SVM__gamma=0.001;, score=(train=0.929, test=0.903) total time=   1.9s\n",
      "[CV 5/5] END SVM__C=10.0, SVM__gamma=0.001;, score=(train=0.922, test=0.919) total time=   1.4s\n",
      "[CV 1/5] END SVM__C=10.0, SVM__gamma=0.01;, score=(train=0.987, test=0.965) total time=   1.0s\n",
      "[CV 2/5] END SVM__C=10.0, SVM__gamma=0.01;, score=(train=0.987, test=0.956) total time=   0.8s\n",
      "[CV 3/5] END SVM__C=10.0, SVM__gamma=0.01;, score=(train=0.988, test=0.958) total time=   0.8s\n",
      "[CV 4/5] END SVM__C=10.0, SVM__gamma=0.01;, score=(train=0.989, test=0.947) total time=   0.8s\n",
      "[CV 5/5] END SVM__C=10.0, SVM__gamma=0.01;, score=(train=0.987, test=0.963) total time=   0.8s\n",
      "[CV 1/5] END SVM__C=10.0, SVM__gamma=0.1;, score=(train=1.000, test=0.978) total time=   3.4s\n",
      "[CV 2/5] END SVM__C=10.0, SVM__gamma=0.1;, score=(train=1.000, test=0.964) total time=   3.1s\n",
      "[CV 3/5] END SVM__C=10.0, SVM__gamma=0.1;, score=(train=1.000, test=0.969) total time=   3.1s\n",
      "[CV 4/5] END SVM__C=10.0, SVM__gamma=0.1;, score=(train=1.000, test=0.958) total time=   3.0s\n",
      "[CV 5/5] END SVM__C=10.0, SVM__gamma=0.1;, score=(train=1.000, test=0.971) total time=   3.8s\n",
      "[CV 1/5] END SVM__C=10.0, SVM__gamma=1.0;, score=(train=1.000, test=0.280) total time=   6.0s\n",
      "[CV 2/5] END SVM__C=10.0, SVM__gamma=1.0;, score=(train=1.000, test=0.267) total time=   6.4s\n",
      "[CV 3/5] END SVM__C=10.0, SVM__gamma=1.0;, score=(train=1.000, test=0.273) total time=   6.3s\n",
      "[CV 4/5] END SVM__C=10.0, SVM__gamma=1.0;, score=(train=1.000, test=0.274) total time=   6.2s\n",
      "[CV 5/5] END SVM__C=10.0, SVM__gamma=1.0;, score=(train=1.000, test=0.278) total time=   6.8s\n",
      "[CV 1/5] END SVM__C=10.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.2s\n",
      "[CV 2/5] END SVM__C=10.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.7s\n",
      "[CV 3/5] END SVM__C=10.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   6.9s\n",
      "[CV 4/5] END SVM__C=10.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   6.9s\n",
      "[CV 5/5] END SVM__C=10.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.2s\n",
      "[CV 1/5] END SVM__C=10.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  10.5s\n",
      "[CV 2/5] END SVM__C=10.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  12.0s\n",
      "[CV 3/5] END SVM__C=10.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  13.3s\n",
      "[CV 4/5] END SVM__C=10.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  11.3s\n",
      "[CV 5/5] END SVM__C=10.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  10.5s\n",
      "[CV 1/5] END SVM__C=10.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.5s\n",
      "[CV 2/5] END SVM__C=10.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.3s\n",
      "[CV 3/5] END SVM__C=10.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  13.0s\n",
      "[CV 4/5] END SVM__C=10.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  11.5s\n",
      "[CV 5/5] END SVM__C=10.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.7s\n",
      "[CV 1/5] END SVM__C=100.0, SVM__gamma=0.001;, score=(train=0.947, test=0.939) total time=   1.1s\n",
      "[CV 2/5] END SVM__C=100.0, SVM__gamma=0.001;, score=(train=0.951, test=0.918) total time=   1.0s\n",
      "[CV 3/5] END SVM__C=100.0, SVM__gamma=0.001;, score=(train=0.951, test=0.933) total time=   0.9s\n",
      "[CV 4/5] END SVM__C=100.0, SVM__gamma=0.001;, score=(train=0.951, test=0.918) total time=   0.9s\n",
      "[CV 5/5] END SVM__C=100.0, SVM__gamma=0.001;, score=(train=0.950, test=0.931) total time=   1.0s\n",
      "[CV 1/5] END SVM__C=100.0, SVM__gamma=0.01;, score=(train=1.000, test=0.962) total time=   0.8s\n",
      "[CV 2/5] END SVM__C=100.0, SVM__gamma=0.01;, score=(train=1.000, test=0.953) total time=   0.8s\n",
      "[CV 3/5] END SVM__C=100.0, SVM__gamma=0.01;, score=(train=1.000, test=0.957) total time=   0.9s\n",
      "[CV 4/5] END SVM__C=100.0, SVM__gamma=0.01;, score=(train=1.000, test=0.952) total time=   0.8s\n",
      "[CV 5/5] END SVM__C=100.0, SVM__gamma=0.01;, score=(train=1.000, test=0.963) total time=   0.9s\n",
      "[CV 1/5] END SVM__C=100.0, SVM__gamma=0.1;, score=(train=1.000, test=0.978) total time=   3.9s\n",
      "[CV 2/5] END SVM__C=100.0, SVM__gamma=0.1;, score=(train=1.000, test=0.964) total time=   3.0s\n",
      "[CV 3/5] END SVM__C=100.0, SVM__gamma=0.1;, score=(train=1.000, test=0.969) total time=   3.0s\n",
      "[CV 4/5] END SVM__C=100.0, SVM__gamma=0.1;, score=(train=1.000, test=0.958) total time=   3.0s\n",
      "[CV 5/5] END SVM__C=100.0, SVM__gamma=0.1;, score=(train=1.000, test=0.971) total time=   3.1s\n",
      "[CV 1/5] END SVM__C=100.0, SVM__gamma=1.0;, score=(train=1.000, test=0.280) total time=   5.8s\n",
      "[CV 2/5] END SVM__C=100.0, SVM__gamma=1.0;, score=(train=1.000, test=0.267) total time=   5.8s\n",
      "[CV 3/5] END SVM__C=100.0, SVM__gamma=1.0;, score=(train=1.000, test=0.273) total time=   5.7s\n",
      "[CV 4/5] END SVM__C=100.0, SVM__gamma=1.0;, score=(train=1.000, test=0.274) total time=   6.1s\n",
      "[CV 5/5] END SVM__C=100.0, SVM__gamma=1.0;, score=(train=1.000, test=0.278) total time=   6.2s\n",
      "[CV 1/5] END SVM__C=100.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   6.9s\n",
      "[CV 2/5] END SVM__C=100.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.0s\n",
      "[CV 3/5] END SVM__C=100.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.9s\n",
      "[CV 4/5] END SVM__C=100.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.2s\n",
      "[CV 5/5] END SVM__C=100.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.4s\n",
      "[CV 1/5] END SVM__C=100.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  10.1s\n",
      "[CV 2/5] END SVM__C=100.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  11.2s\n",
      "[CV 3/5] END SVM__C=100.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=   9.8s\n",
      "[CV 4/5] END SVM__C=100.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  10.0s\n",
      "[CV 5/5] END SVM__C=100.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  12.3s\n",
      "[CV 1/5] END SVM__C=100.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.9s\n",
      "[CV 2/5] END SVM__C=100.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.3s\n",
      "[CV 3/5] END SVM__C=100.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.5s\n",
      "[CV 4/5] END SVM__C=100.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.0s\n",
      "[CV 5/5] END SVM__C=100.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.4s\n",
      "[CV 1/5] END SVM__C=1000.0, SVM__gamma=0.001;, score=(train=0.988, test=0.951) total time=   1.1s\n",
      "[CV 2/5] END SVM__C=1000.0, SVM__gamma=0.001;, score=(train=0.988, test=0.940) total time=   1.0s\n",
      "[CV 3/5] END SVM__C=1000.0, SVM__gamma=0.001;, score=(train=0.987, test=0.946) total time=   1.0s\n",
      "[CV 4/5] END SVM__C=1000.0, SVM__gamma=0.001;, score=(train=0.988, test=0.942) total time=   1.1s\n",
      "[CV 5/5] END SVM__C=1000.0, SVM__gamma=0.001;, score=(train=0.987, test=0.949) total time=   1.0s\n",
      "[CV 1/5] END SVM__C=1000.0, SVM__gamma=0.01;, score=(train=1.000, test=0.960) total time=   1.0s\n",
      "[CV 2/5] END SVM__C=1000.0, SVM__gamma=0.01;, score=(train=1.000, test=0.951) total time=   0.9s\n",
      "[CV 3/5] END SVM__C=1000.0, SVM__gamma=0.01;, score=(train=1.000, test=0.958) total time=   0.9s\n",
      "[CV 4/5] END SVM__C=1000.0, SVM__gamma=0.01;, score=(train=1.000, test=0.953) total time=   1.0s\n",
      "[CV 5/5] END SVM__C=1000.0, SVM__gamma=0.01;, score=(train=1.000, test=0.963) total time=   0.9s\n",
      "[CV 1/5] END SVM__C=1000.0, SVM__gamma=0.1;, score=(train=1.000, test=0.978) total time=   3.1s\n",
      "[CV 2/5] END SVM__C=1000.0, SVM__gamma=0.1;, score=(train=1.000, test=0.964) total time=   3.3s\n",
      "[CV 3/5] END SVM__C=1000.0, SVM__gamma=0.1;, score=(train=1.000, test=0.969) total time=   3.2s\n",
      "[CV 4/5] END SVM__C=1000.0, SVM__gamma=0.1;, score=(train=1.000, test=0.958) total time=   3.1s\n",
      "[CV 5/5] END SVM__C=1000.0, SVM__gamma=0.1;, score=(train=1.000, test=0.971) total time=   3.0s\n",
      "[CV 1/5] END SVM__C=1000.0, SVM__gamma=1.0;, score=(train=1.000, test=0.280) total time=   5.7s\n",
      "[CV 2/5] END SVM__C=1000.0, SVM__gamma=1.0;, score=(train=1.000, test=0.267) total time=   6.7s\n",
      "[CV 3/5] END SVM__C=1000.0, SVM__gamma=1.0;, score=(train=1.000, test=0.273) total time=   8.3s\n",
      "[CV 4/5] END SVM__C=1000.0, SVM__gamma=1.0;, score=(train=1.000, test=0.274) total time=   5.9s\n",
      "[CV 5/5] END SVM__C=1000.0, SVM__gamma=1.0;, score=(train=1.000, test=0.278) total time=   6.4s\n",
      "[CV 1/5] END SVM__C=1000.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   8.5s\n",
      "[CV 2/5] END SVM__C=1000.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.7s\n",
      "[CV 3/5] END SVM__C=1000.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.1s\n",
      "[CV 4/5] END SVM__C=1000.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.7s\n",
      "[CV 5/5] END SVM__C=1000.0, SVM__gamma=10.0;, score=(train=1.000, test=0.115) total time=   7.2s\n",
      "[CV 1/5] END SVM__C=1000.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  12.7s\n",
      "[CV 2/5] END SVM__C=1000.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  12.7s\n",
      "[CV 3/5] END SVM__C=1000.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  13.6s\n",
      "[CV 4/5] END SVM__C=1000.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  10.1s\n",
      "[CV 5/5] END SVM__C=1000.0, SVM__gamma=100.0;, score=(train=1.000, test=0.115) total time=  11.2s\n",
      "[CV 1/5] END SVM__C=1000.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.4s\n",
      "[CV 2/5] END SVM__C=1000.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.7s\n",
      "[CV 3/5] END SVM__C=1000.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=  10.1s\n",
      "[CV 4/5] END SVM__C=1000.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=   9.3s\n",
      "[CV 5/5] END SVM__C=1000.0, SVM__gamma=1000.0;, score=(train=1.000, test=0.115) total time=   9.4s\n",
      "Grid scaled training score for libsvm is: 100.0 %\n",
      "Grid scaled test score for libsvm is: 96.875 %\n",
      "The Best parameters according to grid search are: {'SVM__C': 10.0, 'SVM__gamma': 0.1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_name = 'train_set.csv'\n",
    "split_frac = 0.9\n",
    "num_ft=25\n",
    "random_state = 69420\n",
    "low_reg, high_reg = -2,3\n",
    "low_cof, high_cof = -3,1\n",
    "low_deg, high_deg = 1,3\n",
    "\n",
    "reg_pam = np.logspace(low_reg, high_reg, num=1+high_reg-low_reg)\n",
    "ker_coeff_pam = np.logspace(low_cof, high_cof, num=1+high_cof-low_cof)\n",
    "deg_pam = np.linspace(low_deg, high_deg, 1+high_deg-low_deg)\n",
    "\n",
    "\n",
    "df = pd.read_csv(file_name, header=None)\n",
    "\n",
    "print(\"#################################################################################\")\n",
    "# print(\"Labels:\",lab1, \",\", lab2)\n",
    "print(\"Number of features:\", num_ft)\n",
    "print(\"#################################################################################\")\n",
    "\n",
    "#CONVERT TO USE\n",
    "df_temp = df\n",
    "#print(len(df_temp))\n",
    "# df_temp.iloc[df_temp[25] == lab1, 25] = -1\n",
    "# df_temp.iloc[df_temp[25] == lab2, 25] = 1\n",
    "df_temp = df_temp.sample(frac=1., random_state=random_state)\n",
    "\n",
    "# SPLIT IN TRAIN AND TEST\n",
    "train_df = df_temp[:int(split_frac*len(df_temp))]\n",
    "test_df = df_temp[int(split_frac*len(df_temp)):]\n",
    "\n",
    "# SPLIT BY FEATURES\n",
    "X_train_temp = train_df.loc[:, [i for i in range(num_ft)]]\n",
    "y_train_temp = train_df.loc[:, [25]]\n",
    "X_test_temp = test_df.loc[:, [i for i in range(num_ft)]]\n",
    "y_test_temp = test_df.loc[:, [25]]\n",
    "\n",
    "\n",
    "\n",
    "train_X = np.array(X_train_temp.values)\n",
    "train_y = np.array(y_train_temp.values)\n",
    "test_X = np.array(X_test_temp.values)\n",
    "test_y = np.array(y_test_temp.values)\n",
    "\n",
    "print (\"Number of training examples:\", train_X.shape, train_y.shape)\n",
    "print (\"Number of test examples:\", test_X.shape, test_y.shape)\n",
    "\n",
    "typ = ['linear','sigmoid','poly','rbf']\n",
    "# typ = ['rbf']\n",
    "for which in typ:\n",
    "    # SVM STUFF & GRID SEARCH CV\n",
    "    print(\"--------------------------LIBSVM for {ty}-----------------------------\".format(ty=which.upper()))\n",
    "    if (which=='linear'):\n",
    "        ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='linear'))]\n",
    "        parameters = {'SVM__C':reg_pam} #Linear\n",
    "    elif (which=='rbf' or which=='sigmoid'):\n",
    "        ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel=which))]\n",
    "        parameters = {'SVM__C':reg_pam, 'SVM__gamma':ker_coeff_pam} #RBF/SIGMOID\n",
    "    elif (which=='poly'):\n",
    "        ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='poly'))]\n",
    "        parameters = {'SVM__C':reg_pam, 'SVM__degree':deg_pam, 'SVM__gamma':ker_coeff_pam} #Poly\n",
    "\n",
    "    pipeline = Pipeline(ppl) \n",
    "    grid = GridSearchCV(pipeline, param_grid=parameters, cv=5, return_train_score=True, verbose=3)\n",
    "\n",
    "    grid.fit(train_X, np.ravel(train_y, order='C'))\n",
    "    print(\"Grid scaled training score for libsvm is:\", 100*grid.score(train_X, train_y), \"%\")\n",
    "    print(\"Grid scaled test score for libsvm is:\", 100*grid.score(test_X, test_y), \"%\")\n",
    "    bestpar = grid.best_params_\n",
    "    print(\"The Best parameters according to grid search are:\", bestpar)\n",
    "\n",
    "    # mod = svm.SVC(kernel='linear', C = bestpar['SVM__C']) #Linear\n",
    "    # mod = svm.SVC(kernel='poly', C = bestpar['SVM__C'], gamma = bestpar['SVM__gamma'], degree= bestpar['SVM__degree']) #Poly\n",
    "    # mod = svm.SVC(kernel='sigmoid', C = bestpar['SVM__C'], gamma = bestpar['SVM__gamma']) #RBF\n",
    "\n",
    "    # mod.fit(train_X, np.ravel(train_y, order='C'))\n",
    "    # print(\"Training score for LIBSVM with best parameters:\", 100*mod.score(train_X, train_y), \"%\")\n",
    "    # print(\"Test score for LIBSVM with best parameters:\", 100*mod.score(test_X, test_y), \"%\")\n",
    "\n",
    "\n",
    "\n",
    "    # PLOTTINGS\n",
    "    if (which=='linear'):\n",
    "        plot_it_all_linear(train_X, train_y, test_X, test_y, reg_pam) #Linear. Nothing for anything else. Can use other one for RBF\n",
    "        plot_search_results_linear(grid, reg_pam) #Linear\n",
    "    # plot_it_all_rbf(train_X, train_y, test_X, test_y, reg_pam, ker_coeff_pam)\n",
    "    else:\n",
    "        plot_search_results(grid) #For non-linear or any with multiple parameters\n",
    "\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84612ec9-1eda-4229-a94f-7c2428e42f64",
   "metadata": {},
   "source": [
    "### Running for final output of best model (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f010ddc-791e-4ab5-8941-fb1f8657108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[1. 1. 1. ... 0. 2. 7.]\n",
      "22_10_19_26_54\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "k = str(now).split(':')\n",
    "p = k[0][-2:] + '_' + k[1] + '_' + k[2].split('.')[0]\n",
    "p=k[0].split('-')[2][:2]+'_'+k[0].split('-')[1]+'_'+p\n",
    "\n",
    "num_ft=25\n",
    "\n",
    "df = pd.read_csv(\"train_set.csv\", header=None)\n",
    "df_temp = df.sample(frac=1., random_state=random_state)\n",
    "X_train_temp = df_temp.loc[:, [i for i in range(num_ft)]]\n",
    "y_train_temp = df_temp.loc[:, [25]]\n",
    "train_X = np.array(X_train_temp.values)\n",
    "train_y = np.array(y_train_temp.values)\n",
    "\n",
    "df = pd.read_csv(\"test_set.csv\", header=None)\n",
    "df_temp = df\n",
    "test_X = np.array(df_temp.values)\n",
    "\n",
    "ppl = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='rbf', C=100, gamma=0.1))] #1,0.1\n",
    "pipeline = Pipeline(ppl) \n",
    "pipeline.fit(train_X, np.ravel(train_y, order='C'))\n",
    "print(pipeline.score(train_X, train_y))\n",
    "pred_y = pipeline.predict(test_X)\n",
    "id = np.array([i+1 for i in range(len(pred_y))])\n",
    "print(pred_y)\n",
    "print(p)\n",
    "save2csv(\"test_\"+p+\".csv\", pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8e525-7d8a-455a-9dbe-ebc40d37dc50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
